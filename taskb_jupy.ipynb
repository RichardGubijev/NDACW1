{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.io import show\n",
    "from bokeh.plotting import figure, from_networkx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import collections\n",
    "from taska import parseWikiData\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filepath = 'datasets/PROPERTIES_FOR_DELETION_SML.csv'\n",
    "    filepath2 = \"datasets/WIKIPROJECTS_MED.csv\"\n",
    "    filepath3 = \"datasets/USERS_LRG.csv\"\n",
    "\n",
    "    graph1 = parseWikiData(filepath=filepath)\n",
    "    graph2 = parseWikiData(filepath=filepath2)\n",
    "    graph3 = parseWikiData(filepath=filepath3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot using Pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph1, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph2, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph3, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot using Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # If we want to plot the graph = subgraph(largest_component)\n",
    "def bokeh_plot_simple(graph:nx.Graph, title:str, scale=2, crop_factors = None):\n",
    "    \n",
    "    crop_factors = dict(x_range=(-1.1,1.1), y_range=(-1.1,1.1)) \\\n",
    "        if crop_factors is None else crop_factors\n",
    "\n",
    "    plot = figure(\n",
    "        title=title, tools=\"\",\n",
    "        toolbar_location=None, **crop_factors)\n",
    "\n",
    "    mapping = dict((n, i) for i, n in enumerate(graph.nodes))\n",
    "    graph_mapped = nx.relabel_nodes(graph, mapping)\n",
    "\n",
    "    graph_plot = from_networkx(\n",
    "        graph_mapped, nx.spring_layout, scale=scale, center=(0,0))\n",
    "    plot.renderers.append(graph_plot)\n",
    "\n",
    "    #output_file(\"networkx_graph.html\")\n",
    "    show(plot)\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(graph1, 'Graph 1', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(graph2, 'Graph 2', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(graph3, 'Graph 3', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i) Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) graph statistics\n",
    "- Number of Nodes\n",
    "- Number of Edges\n",
    "- Number of Connected Components\n",
    "- Average Degree\n",
    "- Edge with max degree and its degree\n",
    "- Number of isolated nodes\n",
    "- Diameter (impossible if more than 1 Connected Component)\n",
    "- Degree Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_with_highest_degree(graph):\n",
    "    degree_sequence = [d for n, d in graph.degree()]\n",
    "\n",
    "    max_degree = max(degree_sequence)\n",
    "    nodes_with_max_degree = [n for n, d in graph.degree() if d == max_degree]\n",
    "\n",
    "    return(max_degree, nodes_with_max_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isolated_nodes(graph):\n",
    "    nodes_with_0_degree = [n for n, d in graph.degree() if d == 0]\n",
    "\n",
    "    return len(nodes_with_0_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i)1) Graph Statistics\n",
    "def print_graph_statistics(graph:nx.Graph, amount_of_max_degree_nodes:bool=False):\n",
    "    print(\"Number of nodes: {}\\nNumber of edges: {}\".format(\n",
    "        graph.number_of_nodes(), graph.number_of_edges()\n",
    "    ))\n",
    "    print(\"Number of connected components: {}\".format(\n",
    "        nx.algorithms.components.number_connected_components(graph),\n",
    "    ))\n",
    "    print(\"Average degree: {}\\nClustering coefficient: {}\".format(\n",
    "        np.mean([deg for _, deg in graph.degree]),\n",
    "        nx.algorithms.cluster.average_clustering(graph)\n",
    "    ))\n",
    "    max_degree, nodes_with_max_degree = get_nodes_with_highest_degree(graph)\n",
    "    print(f'Max degree: {max_degree}')\n",
    "    print(f'Amount of nodes with max degree:{len(nodes_with_max_degree)}') if amount_of_max_degree_nodes else print(f'Nodes with max degree:{nodes_with_max_degree}')\n",
    "\n",
    "    nodes_with_degree_0 = get_isolated_nodes(graph)\n",
    "    print(f'Number of Isolated nodes:  {(nodes_with_degree_0)}')\n",
    "\n",
    "    try:  # attempt to compute the diameter of the graph\n",
    "        diam = nx.algorithms.approximation.distance_measures.diameter(graph)\n",
    "        print(\"Graph diameter: {}\".format(diam))\n",
    "    except:  # an error has  occurred\n",
    "        print(\"\\nERROR: Could not compute the diameter of the graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 739\n",
      "Number of edges: 13530\n",
      "Number of connected components: 4\n",
      "Average degree: 36.617050067659\n",
      "Clustering coefficient: 0.7913288282706287\n",
      "Max degree: 478\n",
      "Nodes with max degree:['Jura1']\n",
      "Number of Isolated nodes:  2\n",
      "\n",
      "ERROR: Could not compute the diameter of the graph.\n"
     ]
    }
   ],
   "source": [
    "print_graph_statistics(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Count Distribution\n",
    "A histogram representing the degree distribution of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_count_distribution(graph):\n",
    "    degree_sequence = [d for n, d in graph.degree()]\n",
    "    degree_count = collections.Counter(degree_sequence)\n",
    "    deg, cnt = zip(*degree_count.items())\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(deg, cnt, width=0.8)\n",
    "    plt.title('Degree Histogram')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Largest Component Statistics\n",
    "- On top of above statistics add average shortest path\n",
    "- Kevin Bacon Node and it's average path from all other nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_connected_statistics_with_average_shortest_path(component:nx.Graph, amount_of_max_degree_nodes:bool=False):\n",
    "    print(\"Number of nodes: {}\\nNumber of edges: {}\".format(\n",
    "        component.number_of_nodes(), component.number_of_edges()\n",
    "    ))\n",
    "    print(\"Average path length: {}\".format(\n",
    "    nx.average_shortest_path_length(component)\n",
    "    ))\n",
    "    print(\"Number of connected components: {}\".format(\n",
    "        nx.algorithms.components.number_connected_components(component),\n",
    "    ))\n",
    "    print(\"Average degree: {}\\nClustering coefficient: {}\".format(\n",
    "        np.mean([deg for _, deg in component.degree]),\n",
    "        nx.algorithms.cluster.average_clustering(component)\n",
    "    ))\n",
    "\n",
    "    nodes_with_degree_0 = get_isolated_nodes(component)\n",
    "    print(f'Number of Isolated Nodes:  {nodes_with_degree_0}')\n",
    "\n",
    "    max_degree, nodes_with_max_degree = get_nodes_with_highest_degree(component)\n",
    "    print(f'Max degree: {max_degree}')\n",
    "    print(f'Amount of nodes with max degree:{len(nodes_with_max_degree)}') if amount_of_max_degree_nodes else print(f'Nodes with max degree:{nodes_with_max_degree}')\n",
    "\n",
    "\n",
    "    try:  # attempt to compute the diameter of the graph\n",
    "        diam = nx.algorithms.approximation.distance_measures.diameter(component)\n",
    "        print(\"Graph diameter: {}\".format(diam))\n",
    "    except:  # an error has  occurred\n",
    "        print(\"\\nERROR: Could not compute the diameter of the graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics_for_largest_component(graph:nx.Graph, amount_of_max_degree_nodes:bool=False):\n",
    "    largest_component = max(nx.connected_components(graph), key=len)\n",
    "    graph_largest_components = graph.subgraph(largest_component)\n",
    "    print_connected_statistics_with_average_shortest_path(graph_largest_components, amount_of_max_degree_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 735\n",
      "Number of edges: 13529\n",
      "Average path length: 2.1468090233368553\n",
      "Number of connected components: 1\n",
      "Average degree: 36.81360544217687\n",
      "Clustering coefficient: 0.7956353797169995\n",
      "Number of Isolated Nodes:  0\n",
      "Max degree: 478\n",
      "Nodes with max degree:['Jura1']\n",
      "Graph diameter: 4\n"
     ]
    }
   ],
   "source": [
    "print_statistics_for_largest_component(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_count_distribution_largest_component(graph):\n",
    "    degree_sequence = [d for n, d in graph.degree()]\n",
    "    degree_count = collections.Counter(degree_sequence)\n",
    "    deg, cnt = zip(*degree_count.items())\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(deg, cnt, width=0.8)\n",
    "    plt.title('Degree Histogram')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution_largest_component(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution_largest_component(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution_largest_component(graph3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Kevin Bacon node by finding the node with the lowest average path from all other nodes to itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kevin_bacon_node_for_largest_component(graph:nx.Graph):\n",
    "    largest_component = max(nx.connected_components(graph), key=len)\n",
    "    largest_component_graph = graph.subgraph(largest_component)\n",
    "    average_shortest_path_length = []\n",
    "\n",
    "    for node in largest_component_graph.nodes():\n",
    "        path_lengths = nx.single_source_shortest_path_length(largest_component_graph, node)\n",
    "        avg_length = sum(path_lengths.values())/len(path_lengths)\n",
    "        average_shortest_path_length.append((node, avg_length))\n",
    "    \n",
    "    kevin_bacon_node = None\n",
    "    min_average_length = float('inf')\n",
    "    for node, average_length in average_shortest_path_length:\n",
    "        if average_length < min_average_length:\n",
    "            kevin_bacon_node = node\n",
    "            min_average_length = average_length\n",
    "\n",
    "    \n",
    "\n",
    "    print(f'Kevin Bacon node: {kevin_bacon_node}\\nWith average length: {min_average_length}')\n",
    "    return kevin_bacon_node, min_average_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kevin_bacon_node_for_largest_component(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kevin_bacon_node_for_largest_component(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kevin_bacon_node_for_largest_component(graph3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Node level statistics\n",
    "Analyse three different graphs by analysing its properties at the node level\n",
    "- Degrees\n",
    "- Clustering Coefficients\n",
    "- Closeness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_level_descriptors(graph:nx.Graph):\n",
    "    degrees = [d for _, d in graph.degree()]\n",
    "    ccoeffs = [d for _, d in nx.algorithms.cluster.clustering(graph).items()]\n",
    "    ccentra = [d for _, d in nx.closeness_centrality(graph).items()]\n",
    "\n",
    "    return {'degrees': degrees, 'clustering coefficients': ccoeffs, 'closenes centrality': ccentra}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_helper_node_level_descriptors(descriptors, titles, key):\n",
    "    data = {titles[i]: descriptors[i][key] for i in range(len(titles))}\n",
    "    sns.displot(data, height=4, aspect=2, kde=True)\n",
    "    plt.title(f'Distribution of {key} (Count)')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_node_level_descriptors_degrees(graphs:list[nx.Graph], titles:list[str]):\n",
    "    \n",
    "    descriptors = [get_node_level_descriptors(graph) for graph in graphs]\n",
    "    plot_helper_node_level_descriptors(descriptors, titles, 'degrees')\n",
    "\n",
    "def show_node_level_descriptors_clustering_centrality(graphs:list[nx.Graph], titles:list[str]):\n",
    "    \n",
    "    descriptors = [get_node_level_descriptors(graph) for graph in graphs]\n",
    "    plot_helper_node_level_descriptors(descriptors, titles, 'clustering coefficients')\n",
    "\n",
    "def show_node_level_descriptors_closeness_centrality(graphs:list[nx.Graph], titles:list[str]):\n",
    "    \n",
    "    descriptors = [get_node_level_descriptors(graph) for graph in graphs]\n",
    "    plot_helper_node_level_descriptors(descriptors, titles, 'closenes centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) Shortest Paths\n",
    "Find the shortest paths between the two nodes which are farthest apart\n",
    "\n",
    "Use the 2-Sweep method for finding the nodes which are furthest apart, i.e. have the same shortest path length as the diameter of the graph.\n",
    "\n",
    "This will have to be done a single component, check that the largest component indeed contains the farthest shortest path.\n",
    "\n",
    "Methods for finding shortest path:\n",
    "\n",
    "- Dijkstra\n",
    "- Bellman Ford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Djikstra\n",
    "def get_shortest_path_largest_component_Dijkstra(graph:nx.Graph, farthest_nodes:tuple):\n",
    "    start_node, end_node = farthest_nodes\n",
    "\n",
    "    spath = nx.algorithms.dijkstra_path(graph, start_node, end_node)\n",
    "    print(\"\\nShortest path: \" + \" -> \".join([str(n) for n in spath]))\n",
    "\n",
    "    print(\"How long is the path among these farthest nodes? {}\".format(\n",
    "    len(spath) - 1))  # here we do -1 to avoid counting the starting node!\n",
    "    print(f'Should be the same as the diameter of the graph!!!: {nx.algorithms.approximation.distance_measures.diameter(graph)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BF\n",
    "def get_shortest_path_largest_component_BF(graph:nx.Graph, farthest_nodes):\n",
    "    start_node, end_node = farthest_nodes\n",
    "\n",
    "    print(f\"Start node: {start_node}\\nEnd node: {end_node}\") \n",
    "\n",
    "    spath = nx.algorithms.bellman_ford_path(graph, start_node, end_node)\n",
    "    print(\"\\nShortest path: \" + \" -> \".join([str(n) for n in spath]))\n",
    "\n",
    "    print(\"How long is the path among these farthest nodes? {}\".format(\n",
    "    len(spath) - 1))  # here we do -1 to avoid counting the starting node!\n",
    "    print(f'Should be the same as the diameter of the graph!!!: {nx.algorithms.approximation.distance_measures.diameter(graph)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1_largest_component = graph1.subgraph(max(nx.connected_components(graph1), key=len))\n",
    "\n",
    "graph2_largest_component = graph2.subgraph(max(nx.connected_components(graph2), key=len))\n",
    "\n",
    "graph3_largest_component = graph3.subgraph(max(nx.connected_components(graph3), key=len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leveraging the property of the diameter's endpoints being part of the longest shortest path from any node\n",
    "def get_farthest_nodes_2_sweep(graph:nx.Graph):\n",
    "    diameter = nx.algorithms.approximation.distance_measures.diameter(graph)\n",
    "    number_of_nodes = graph.number_of_nodes()\n",
    "    while True:\n",
    "        node = list(graph.nodes())[random.randint(0, number_of_nodes)]\n",
    "\n",
    "        distances_from_node = nx.single_source_shortest_path_length(graph, node)\n",
    "        start_node = max(distances_from_node, key=distances_from_node.get)\n",
    "\n",
    "        distances_from_start_node = nx.single_source_shortest_path_length(graph, start_node)\n",
    "        end_node = max(distances_from_start_node, key=distances_from_start_node.get)\n",
    "\n",
    "        max_length = nx.shortest_path_length(graph, source = start_node, target=end_node)\n",
    "\n",
    "        if(diameter == max_length):\n",
    "            return(start_node, end_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_diam_is_in_component(graph:nx.Graph, largest_component:nx.Graph):\n",
    "    try:\n",
    "        largest_comp_diam = nx.algorithms.approximation.distance_measures.diameter(largest_component)\n",
    "    except:\n",
    "        print('This component has no diameter')\n",
    "        return False\n",
    "\n",
    "    connected_components = [list(component) for component in nx.connected_components(graph)]\n",
    "    for comp in connected_components:\n",
    "        try:  # attempt to compute the diameter of the graph\n",
    "            diam = nx.algorithms.approximation.distance_measures.diameter(graph)\n",
    "            if nx.algorithms.approximation.distance_measures.diameter(comp) > largest_comp_diam:\n",
    "                return False\n",
    "        except:  # an error has  occurred\n",
    "            continue\n",
    "        \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if largest path is in largest component\n",
    "print(f'Graph 1: {check_diam_is_in_component(graph1, graph1_largest_component)}')\n",
    "print(f'Graph 2: {check_diam_is_in_component(graph2, graph2_largest_component)}')\n",
    "print(f'Graph 3: {check_diam_is_in_component(graph3, graph3_largest_component)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1_farthest_nodes = get_farthest_nodes_2_sweep(graph1_largest_component) # diam = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2_farthest_nodes  = get_farthest_nodes_2_sweep(graph2_largest_component) # diam = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have assumed that the largest path will be in the largest component\n",
    "graph3_farthest_nodes = get_farthest_nodes_2_sweep(graph3_largest_component) # diam = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(graph1_largest_component, graph1_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(graph2_largest_component, graph2_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(graph3_largest_component, graph3_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(graph1_largest_component, graph1_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(graph2_largest_component, graph2_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(graph3_largest_component, graph3_farthest_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii) Where is it on random <-> small world <-> regular\n",
    "\n",
    "- Build equivalent Random graph, using Erdos-Renyi\n",
    "- Build equivalent Regular graph\n",
    "\n",
    "\n",
    "To analyse the differences\n",
    "- get statistics for the random graph\n",
    "- get statistics for the largest component of the random graph\n",
    "- get statistics for the regular graph\n",
    "- get the degree distribution for the random graph\n",
    "- get the degree distribution for the regular graph\n",
    "- Calculate the Graph Edit Distance (GED)\n",
    "\n",
    "note: to use this GED implementation, we must preserve node names to allow for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equivalent_random_graph_preserve_nodes(graph:nx.Graph, draw=True):\n",
    "    # n : number of nodes\n",
    "    # p : frequency of edge occurence\n",
    "        # max edges: n (n - 1) / 2\n",
    "        # frequency of edge occurence: number of edges / max edges\n",
    "    n = graph.number_of_nodes()\n",
    "    nodes = list(graph.nodes())\n",
    "    number_of_edges = graph.number_of_edges()\n",
    "    max_edges = n*(n-1)/2\n",
    "    p = number_of_edges/max_edges\n",
    "\n",
    "    equivalent_random = nx.Graph()\n",
    "    equivalent_random.add_nodes_from(nodes)\n",
    "\n",
    "    rng = random.Random(None)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if rng.random() < p:\n",
    "                equivalent_random.add_edge(nodes[i], nodes[j])\n",
    "\n",
    "    nx.draw(equivalent_random, with_labels=False) if draw else 0\n",
    "    print(f'n: {n}\\n p:{p}')\n",
    "    return equivalent_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equivalent_regular_graph_preserve_nodes(graph:nx.Graph, draw=True):\n",
    "    regular_graph = nx.Graph()\n",
    "\n",
    "    nodes = list(graph.nodes())\n",
    "\n",
    "    regular_graph.add_nodes_from(nodes)\n",
    "\n",
    "    n = len(nodes)\n",
    "\n",
    "    for i, node in enumerate(nodes):\n",
    "        next_one = nodes[(i+1)%n]\n",
    "        jump_node = nodes[(i+2)%n]\n",
    "        regular_graph.add_edge(node, next_one)\n",
    "        regular_graph.add_edge(node, jump_node)\n",
    "\n",
    "    if draw:\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        nx.draw(regular_graph, pos=nx.circular_layout(regular_graph), with_labels=False)\n",
    "    return regular_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 739\n",
      " p:0.04961659900766802\n",
      "n: 1620\n",
      " p:0.005171611801218555\n",
      "n: 11387\n",
      " p:0.00038089543160109467\n"
     ]
    }
   ],
   "source": [
    "graph1_equivalent_random = get_equivalent_random_graph_preserve_nodes(graph1, False)\n",
    "graph2_equivalent_random = get_equivalent_random_graph_preserve_nodes(graph2, False)\n",
    "graph3_equivalent_random = get_equivalent_random_graph_preserve_nodes(graph3, False)\n",
    "\n",
    "graph1_equivalent_regular = get_equivalent_regular_graph_preserve_nodes(graph1, False)\n",
    "graph2_equivalent_regular = get_equivalent_regular_graph_preserve_nodes(graph2, False)\n",
    "graph3_equivalent_regular = get_equivalent_regular_graph_preserve_nodes(graph3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 739\n",
      "Number of edges: 13583\n",
      "Number of connected components: 1\n",
      "Average degree: 36.760487144790254\n",
      "Clustering coefficient: 0.049744658240079634\n",
      "Max degree: 59\n",
      "Nodes with max degree:['Gstupp']\n",
      "Number of Isolated nodes:  0\n",
      "Graph diameter: 3\n",
      "\n",
      "\n",
      "Number of nodes: 739\n",
      "Number of edges: 13583\n",
      "Average path length: 2.1018588805644485\n",
      "Number of connected components: 1\n",
      "Average degree: 36.760487144790254\n",
      "Clustering coefficient: 0.049744658240079634\n",
      "Number of Isolated Nodes:  0\n",
      "Max degree: 59\n",
      "Nodes with max degree:['Gstupp']\n",
      "Graph diameter: 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Number of nodes: 739\n",
      "Number of edges: 1478\n",
      "Average path length: 92.75067750677506\n",
      "Number of connected components: 1\n",
      "Average degree: 4.0\n",
      "Clustering coefficient: 0.5\n",
      "Number of Isolated Nodes:  0\n",
      "Max degree: 4\n",
      "Amount of nodes with max degree:739\n",
      "Graph diameter: 185\n"
     ]
    }
   ],
   "source": [
    "print_graph_statistics(graph1_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(graph1_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(graph1_equivalent_regular, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph2_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(graph2_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(graph2_equivalent_regular, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph3_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(graph3_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(graph3_equivalent_regular, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph1_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph2_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph3_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_node_level_comparison(graph:nx.Graph, equivalent_random:nx.Graph, equivalent_regular:nx.Graph):\n",
    "\n",
    "    show_node_level_descriptors_degrees([graph, equivalent_random, equivalent_regular], ['graph', 'random', 'regular'])\n",
    "    print('\\n'*4)\n",
    "    show_node_level_descriptors_clustering_centrality([graph, equivalent_random, equivalent_regular], ['graph', 'random', 'regular'])\n",
    "    print('\\n'*4)\n",
    "    show_node_level_descriptors_closeness_centrality([graph, equivalent_random, equivalent_regular], ['graph', 'random', 'regular'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(graph1, graph1_equivalent_random, graph1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(graph2, graph2_equivalent_random, graph2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(graph3, graph3_equivalent_random, graph3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_edit_distance_approximation(graph1:nx.Graph, graph2:nx.Graph):\n",
    "    graph1_edges = set(graph1.edges())\n",
    "    graph2_edges = set(graph2.edges())\n",
    "\n",
    "\n",
    "    unique_edges_to_graph1 = graph1_edges - graph2_edges\n",
    "    unique_edges_to_graph2 = graph2_edges - graph1_edges\n",
    "\n",
    "    edit_distance = len(unique_edges_to_graph1) + len(unique_edges_to_graph2)\n",
    "    print(f'Unique edges to graph1: {len(unique_edges_to_graph1)}/{len(graph1_edges)}\\nUnique edges to graph2: {len(unique_edges_to_graph2)}/{len(graph2_edges)}\\nApproximation of GED: {edit_distance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_edit_distance_approximation(graph1, graph1_equivalent_random)\n",
    "print('\\n\\n\\n\\n')\n",
    "calculate_edge_edit_distance_approximation(graph1, graph1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_edit_distance_approximation(graph2, graph2_equivalent_random)\n",
    "print('\\n\\n\\n\\n')\n",
    "calculate_edge_edit_distance_approximation(graph2, graph2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_edit_distance_approximation(graph3, graph3_equivalent_random)\n",
    "print('\\n\\n\\n\\n')\n",
    "calculate_edge_edit_distance_approximation(graph3, graph3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v) Two editors are connected iff they have both contributed to any thread in the same page, but not necessarily to the same thread? ( I.e. we would have more connections in the network)\n",
    "\n",
    "i.e. Redefine the graphs, rename them as net1, net2, and net3\n",
    "\n",
    "Analyse the resulting graphs with the methods identified above\n",
    "i.e.\n",
    "- plot the graphs (bokeh and matplotlib.pyplot)\n",
    "- graph statistics\n",
    "- largest component of the graphs statistics\n",
    "- Shortest paths using Dijkstra and Bellman Ford\n",
    "- Where is it on the random <-> small world <-> regular continuum\n",
    "    - statistics (as outlined above)\n",
    "    - degree distributions for the three graphs\n",
    "    - Node level comparisons (Degrees, Clustering Centrality, Closeness Centrality)\n",
    "    - Graph Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_connected_by_thread_in_same_page(network_data:str):\n",
    "    net = pd.read_csv(network_data)\n",
    "\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    for page, dataframe in net.groupby('page_name'):\n",
    "        nodes = dataframe['username'].unique()\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range (i + 1, len(nodes)):\n",
    "                graph.add_edge(nodes[i], nodes[j])\n",
    "\n",
    "    return graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = create_graph_connected_by_thread_in_same_page('datasets/PROPERTIES_FOR_DELETION_SML.csv')\n",
    "net2 = create_graph_connected_by_thread_in_same_page(\"datasets/WIKIPROJECTS_MED.csv\")\n",
    "net3 = create_graph_connected_by_thread_in_same_page(\"datasets/USERS_LRG.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(net1, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(net2, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(net3, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(net1, 'Net 1', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(net2, 'Net 2', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(net3, 'Net 3', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest Component Graph Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kevin_bacon_node_for_largest_component(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kevin_bacon_node_for_largest_component(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kevin_bacon_node_for_largest_component(net3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net1_largest_component = net1.subgraph(max(nx.connected_components(net1), key=len))\n",
    "\n",
    "net2_largest_component = net2.subgraph(max(nx.connected_components(net2), key=len))\n",
    "\n",
    "net3_largest_component = net3.subgraph(max(nx.connected_components(net3), key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Net 1: {check_diam_is_in_component(net1, net1_largest_component)}')\n",
    "print(f'Net 2: {check_diam_is_in_component(net2, net2_largest_component)}')\n",
    "print(f'Net 3: {check_diam_is_in_component(net3, net3_largest_component)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1_farthest_nodes  = get_farthest_nodes_2_sweep(net1_largest_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2_farthest_nodes  = get_farthest_nodes_2_sweep(net2_largest_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3_farthest_nodes  = get_farthest_nodes_2_sweep(net3_largest_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(net1_largest_component, net1_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(net2_largest_component, net2_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(net3_largest_component, net3_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(net1_largest_component, net1_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(net2_largest_component, net2_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(net3_largest_component, net3_farthest_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where on the random <-> small world <-> regular continuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1_equivalent_random = get_equivalent_random_graph_preserve_nodes(net1, False)\n",
    "net2_equivalent_random = get_equivalent_random_graph_preserve_nodes(net2, False)\n",
    "net3_equivalent_random = get_equivalent_random_graph_preserve_nodes(net3, False)\n",
    "\n",
    "net1_equivalent_regular = get_equivalent_regular_graph_preserve_nodes(net1, False)\n",
    "net2_equivalent_regular = get_equivalent_regular_graph_preserve_nodes(net2, False)\n",
    "net3_equivalent_regular = get_equivalent_regular_graph_preserve_nodes(net3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Statistics (For Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net1_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(net1_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(net1_equivalent_regular, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net2_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(net2_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(net2_equivalent_regular, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net3_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(net3_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(net3_equivalent_regular, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree Count Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net1_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net2_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net3_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node Level Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(net1, net1_equivalent_random, net1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(net2, net2_equivalent_random, net2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(net3, net3_equivalent_random, net3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_edit_distance_approximation(net1, net1_equivalent_random)\n",
    "print('\\n\\n\\n\\n')\n",
    "calculate_edge_edit_distance_approximation(net1, net1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_edit_distance_approximation(net2, net2_equivalent_random)\n",
    "print('\\n\\n\\n\\n')\n",
    "calculate_edge_edit_distance_approximation(net2, net2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_edit_distance_approximation(net3, net3_equivalent_random)\n",
    "print('\\n\\n\\n\\n')\n",
    "calculate_edge_edit_distance_approximation(net3, net3_equivalent_regular)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
