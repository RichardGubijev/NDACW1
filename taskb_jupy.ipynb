{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.io import output_file, show, save\n",
    "from bokeh.plotting import figure, from_networkx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import collections\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    nodes = data['username'].unique()\n",
    "\n",
    "    for node in nodes:\n",
    "        graph.add_node(node)\n",
    "\n",
    "    grouped_by_page_and_thread = data.groupby(['page_name', 'thread_subject'])\n",
    "\n",
    "    for page_and_thread, dataframe in grouped_by_page_and_thread:\n",
    "        users = dataframe['username'].unique()\n",
    "        for i in range(len(users)):\n",
    "            for j in range(i + 1, len(users)):\n",
    "                graph.add_edge(users[i], users[j])\n",
    "\n",
    "    return graph\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filepath = 'datasets/PROPERTIES_FOR_DELETION_SML.csv'\n",
    "    filepath2 = \"datasets/WIKIPROJECTS_MED.csv\"\n",
    "    filepath3 = \"datasets/USERS_LRG.csv\"\n",
    "\n",
    "    graph1 = parseData(filepath=filepath)\n",
    "    graph2 = parseData(filepath=filepath2)\n",
    "    graph3 = parseData(filepath=filepath3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph1, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph2, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph3, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # If we want to plot the graph = subgraph(largest_component)\n",
    "def bokeh_plot_simple(graph:nx.Graph, title:str, scale=2, crop_factors = None):\n",
    "    \n",
    "    crop_factors = dict(x_range=(-1.1,1.1), y_range=(-1.1,1.1)) \\\n",
    "        if crop_factors is None else crop_factors\n",
    "\n",
    "    plot = figure(\n",
    "        title=title, tools=\"\",\n",
    "        toolbar_location=None, **crop_factors)\n",
    "\n",
    "    mapping = dict((n, i) for i, n in enumerate(graph.nodes))\n",
    "    graph_mapped = nx.relabel_nodes(graph, mapping)\n",
    "\n",
    "    graph_plot = from_networkx(\n",
    "        graph_mapped, nx.spring_layout, scale=scale, center=(0,0))\n",
    "    plot.renderers.append(graph_plot)\n",
    "\n",
    "    #output_file(\"networkx_graph.html\")\n",
    "    show(plot)\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(graph1, 'Graph 1', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(graph2, 'Graph 2', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(graph3, 'Graph 3', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) graph statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_with_highest_degree(graph):\n",
    "    degree_sequence = [d for n, d in graph.degree()]\n",
    "\n",
    "    max_degree = max(degree_sequence)\n",
    "    nodes_with_max_degree = [n for n, d in graph.degree() if d == max_degree]\n",
    "\n",
    "    return(max_degree, nodes_with_max_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i)1) Graph Statistics\n",
    "def print_graph_statistics(graph:nx.Graph):\n",
    "    print(\"Number of nodes: {}\\nNumber of edges: {}\".format(\n",
    "        graph.number_of_nodes(), graph.number_of_edges()\n",
    "    ))\n",
    "    print(\"Number of connected components: {}\".format(\n",
    "        nx.algorithms.components.number_connected_components(graph),\n",
    "    ))\n",
    "    print(\"Average degree: {}\\nClustering coefficient: {}\".format(\n",
    "        np.mean([deg for _, deg in graph.degree]),\n",
    "        nx.algorithms.cluster.average_clustering(graph)\n",
    "    ))\n",
    "    max_degree, nodes_with_max_degree = get_nodes_with_highest_degree(graph)\n",
    "    print(f'Max degree: {max_degree}\\nNodes with max degree:{nodes_with_max_degree}')\n",
    "\n",
    "    try:  # attempt to compute the diameter of the graph\n",
    "        diam = nx.algorithms.approximation.distance_measures.diameter(graph)\n",
    "        print(\"Graph diameter: {}\".format(diam))\n",
    "    except:  # an error has  occurred\n",
    "        print(\"\\nERROR: Could not compute the diameter of the graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_count_distribution(graph):\n",
    "    degree_sequence = [d for n, d in graph.degree()]\n",
    "    degree_count = collections.Counter(degree_sequence)\n",
    "    deg, cnt = zip(*degree_count.items())\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(deg, cnt, width=0.8)\n",
    "    plt.title('Degree Histogram')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) high level stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_connected_statistics_with_average_shortest_path(component:nx.Graph):\n",
    "    print(\"Number of nodes: {}\\nNumber of edges: {}\".format(\n",
    "        component.number_of_nodes(), component.number_of_edges()\n",
    "    ))\n",
    "    print(\"Average path length: {}\".format(\n",
    "    nx.average_shortest_path_length(component)\n",
    "    ))\n",
    "    print(\"Number of connected components: {}\".format(\n",
    "        nx.algorithms.components.number_connected_components(component),\n",
    "    ))\n",
    "    print(\"Average degree: {}\\nClustering coefficient: {}\".format(\n",
    "        np.mean([deg for _, deg in component.degree]),\n",
    "        nx.algorithms.cluster.average_clustering(component)\n",
    "    ))\n",
    "    max_degree, nodes_with_max_degree = get_nodes_with_highest_degree(graph)\n",
    "    print(f'Max degree: {max_degree}\\nNodes with max degree:{nodes_with_max_degree}')\n",
    "\n",
    "\n",
    "    try:  # attempt to compute the diameter of the graph\n",
    "        diam = nx.algorithms.approximation.distance_measures.diameter(component)\n",
    "        print(\"Graph diameter: {}\".format(diam))\n",
    "    except:  # an error has  occurred\n",
    "        print(\"\\nERROR: Could not compute the diameter of the graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics_for_largest_component(graph:nx.Graph):\n",
    "    largest_component = max(nx.connected_components(graph), key=len)\n",
    "    graph_largest_components = graph.subgraph(largest_component)\n",
    "    print_connected_statistics_with_average_shortest_path(graph_largest_components)\n",
    "    #Could do for all components\n",
    "    # for i, conn_component in enumerate(\n",
    "    #     nx.connected_components(graph)):\n",
    "    #     print(f\"[Graph component {i}]\")\n",
    "    #     sub_graph = graph.subgraph(conn_component)  # XXX Careful to manupulations!\n",
    "    #     print_connected_component_statistics(sub_graph)\n",
    "    #     print(\"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_count_distribution_largest_component(graph):\n",
    "    degree_sequence = [d for n, d in graph.degree()]\n",
    "    degree_count = collections.Counter(degree_sequence)\n",
    "    deg, cnt = zip(*degree_count.items())\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(deg, cnt, width=0.8)\n",
    "    plt.title('Degree Histogram')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution_largest_component(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution_largest_component(graph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution_largest_component(graph3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Node level statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_level_descriptors(graph:nx.Graph):\n",
    "    degrees = [d for _, d in graph.degree()]\n",
    "    degree_centrality = [d for _, d in nx.degree_centrality(graph).items()]\n",
    "    ccoeffs = [d for _, d in nx.algorithms.cluster.clustering(graph).items()]\n",
    "    ccentra = [d for _, d in nx.closeness_centrality(graph).items()]\n",
    "\n",
    "    return {'degrees': degrees, 'degree_centrality': degree_centrality, 'clustering coefficients': ccoeffs, 'closenes centrality': ccentra}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_helper_node_level_descriptors(descriptors, titles, key):\n",
    "    data = {titles[i]: descriptors[i][key] for i in range(len(titles))}\n",
    "    sns.displot(data, height=4, aspect=2, kde=True)\n",
    "\n",
    "\n",
    "def show_node_level_descriptors_degrees(graphs=[graph1, graph2, graph3], titles=['graph1', 'graph2', 'graph3']):\n",
    "    \n",
    "    descriptors = [get_node_level_descriptors(graph) for graph in graphs]\n",
    "\n",
    "    print('Degrees')\n",
    "    plot_helper_node_level_descriptors(descriptors, titles, 'degrees')\n",
    "\n",
    "def show_node_level_descriptors_clustering_centrality(graphs=[graph1, graph2, graph3], titles=['graph1', 'graph2', 'graph3']):\n",
    "    \n",
    "    descriptors = [get_node_level_descriptors(graph) for graph in graphs]\n",
    "\n",
    "    print('Clustering Coefficient')\n",
    "    plot_helper_node_level_descriptors(descriptors, titles, 'clustering coefficients')\n",
    "\n",
    "def show_node_level_descriptors_closeness_centrality(graphs=[graph1, graph2, graph3], titles=['graph1', 'graph2', 'graph3']):\n",
    "    \n",
    "    descriptors = [get_node_level_descriptors(graph) for graph in graphs]\n",
    "\n",
    "    print('Closeness Centrality')\n",
    "    plot_helper_node_level_descriptors(descriptors, titles, 'closenes centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show_node_level_descriptors_degrees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_node_level_descriptors_clustering_centrality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_node_level_descriptors_closeness_centrality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) Shortest Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Djikstra\n",
    "def get_shortest_path_largest_component_Dijkstra(graph:nx.Graph, farthest_nodes:tuple):\n",
    "    start_node, end_node = farthest_nodes\n",
    "\n",
    "    spath = nx.algorithms.dijkstra_path(graph, start_node, end_node)\n",
    "    print(\"\\nShortest path: \" + \" -> \".join([str(n) for n in spath]))\n",
    "\n",
    "    print(\"How long is the path among these farthest nodes? {}\".format(\n",
    "    len(spath) - 1))  # here we do -1 to avoid counting the starting node!\n",
    "    print(f'Should be the same as the diameter of the graph!!!: {nx.algorithms.approximation.distance_measures.diameter(graph)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BF\n",
    "def get_shortest_path_largest_component_BF(graph:nx.Graph, farthest_nodes):\n",
    "    start_node, end_node = farthest_nodes\n",
    "\n",
    "    print(f\"Start node: {start_node}\\nEnd node: {end_node}\") \n",
    "\n",
    "    spath = nx.algorithms.bellman_ford_path(graph, start_node, end_node)\n",
    "    print(\"\\nShortest path: \" + \" -> \".join([str(n) for n in spath]))\n",
    "\n",
    "    print(\"How long is the path among these farthest nodes? {}\".format(\n",
    "    len(spath) - 1))  # here we do -1 to avoid counting the starting node!\n",
    "    print(f'Should be the same as the diameter of the graph!!!: {nx.algorithms.approximation.distance_measures.diameter(graph)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1_largest_component = graph1.subgraph(max(nx.connected_components(graph1), key=len))\n",
    "\n",
    "graph2_largest_component = graph2.subgraph(max(nx.connected_components(graph2), key=len))\n",
    "\n",
    "graph3_largest_component = graph3.subgraph(max(nx.connected_components(graph3), key=len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spinner_chars = itertools.cycle('|/-\\\\')  # Create a cycle iterator for the spinner\n",
    "\n",
    "\n",
    "def update_spinner(spinner_chars, percent):\n",
    "    sys.stdout.write('\\r' + 'Loading: ' + next(spinner_chars) + '   ' + str(round(percent, 2)) + '% ')\n",
    "    sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_farthest_nodes(graph):\n",
    "    max_length = 0\n",
    "    farthest_nodes = None\n",
    "    graph_diam = nx.algorithms.approximation.distance_measures.diameter(graph)\n",
    "    size = len(graph.nodes())\n",
    "    size *= len(graph.nodes())\n",
    "    iter = 0\n",
    "\n",
    "    for possible_start_node in graph.nodes():\n",
    "        update_spinner(spinner_chars, (iter*100/size))\n",
    "        for possible_end_node in graph.nodes():\n",
    "            if possible_start_node != possible_end_node:\n",
    "                iter += 1\n",
    "                try:\n",
    "                    update_spinner(spinner_chars, (iter*100/size))\n",
    "                    length = nx.shortest_path_length(graph, source = possible_start_node, target=possible_end_node, method='dijkstra')\n",
    "                    if length > max_length:\n",
    "                        max_length = length\n",
    "                        farthest_nodes = (possible_start_node, possible_end_node)\n",
    "                    elif max_length == graph_diam:\n",
    "                        update_spinner(spinner_chars, (iter*100/size))\n",
    "                        return farthest_nodes\n",
    "                except nx.NetworkXNoPath:\n",
    "                    continue\n",
    "                    \n",
    "\n",
    "    return farthest_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leveraging the property of the diameter's endpoints being part of the longest shortest path from any node\n",
    "def get_farthest_nodes_efficient(graph:nx.Graph):\n",
    "    node = list(graph.nodes())[0]\n",
    "\n",
    "    distances_from_node = nx.single_source_shortest_path_length(graph, node)\n",
    "    start_node = max(distances_from_node, key=distances_from_node.get)\n",
    "\n",
    "    distances_from_start_node = nx.single_source_shortest_path_length(graph, start_node)\n",
    "    end_node = max(distances_from_start_node, key=distances_from_start_node.get)\n",
    "\n",
    "    return(start_node, end_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_diam_is_in_component(graph:nx.Graph, largest_component:nx.Graph):\n",
    "    try:\n",
    "        largest_comp_diam = nx.algorithms.approximation.distance_measures.diameter(largest_component)\n",
    "    except:\n",
    "        print('This component has no diameter')\n",
    "        return False\n",
    "\n",
    "    connected_components = [list(component) for component in nx.connected_components(graph)]\n",
    "    for comp in connected_components:\n",
    "        try:  # attempt to compute the diameter of the graph\n",
    "            diam = nx.algorithms.approximation.distance_measures.diameter(graph)\n",
    "            if nx.algorithms.approximation.distance_measures.diameter(comp) > largest_comp_diam:\n",
    "                return False\n",
    "        except:  # an error has  occurred\n",
    "            continue\n",
    "        \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if largest path is in largest component\n",
    "print('Graph 1:')\n",
    "print(check_diam_is_in_component(graph1, graph1_largest_component))\n",
    "print('\\nGraph 2: ')\n",
    "print(check_diam_is_in_component(graph2, graph2_largest_component))\n",
    "print('\\nGraph 3:')\n",
    "print(check_diam_is_in_component(graph3, graph3_largest_component))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1_farthest_nodes = get_farthest_nodes_efficient(graph1_largest_component) # diam = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2_farthest_nodes  = get_farthest_nodes_efficient(graph2_largest_component) # diam = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have assumed that the largest path will be in the largest component\n",
    "graph3_farthest_nodes = get_farthest_nodes_efficient(graph3_largest_component) # diam = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(graph1_largest_component, graph1_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(graph2_largest_component, graph2_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(graph3_largest_component, graph3_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(graph1_largest_component, graph1_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(graph2_largest_component, graph2_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(graph3_largest_component, graph3_farthest_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii) Where is it on random <-> small world <-> regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equivalent_random_graph(graph:nx.Graph, draw=True):\n",
    "    # n : number of nodes\n",
    "    # p : frequency of edge occurence\n",
    "        # max edges: n (n - 1) / 2\n",
    "        # frequency of edge occurence: number of edges / max edges\n",
    "    n = graph.number_of_nodes()\n",
    "    number_edges = graph.number_of_edges()\n",
    "    max_edges = n*(n-1)/2\n",
    "    p = number_edges/max_edges\n",
    "    equivalen_random =  nx.erdos_renyi_graph(n=n, p=p)\n",
    "    \n",
    "    nx.draw(equivalen_random, with_labels=False) if draw else 0\n",
    "    return equivalen_random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_equivalent_regular_graph(graph:nx.Graph, draw=True):\n",
    "    regular_graph = nx.Graph()\n",
    "\n",
    "    nodes = graph.number_of_nodes()\n",
    "\n",
    "    regular_graph.add_nodes_from(list(range(nodes)))\n",
    "\n",
    "    #list_nodes = list(graph.nodes())\n",
    "    for node in regular_graph:\n",
    "        next_one = (node + 1) % nodes \n",
    "        jump_node = (node + 2) % nodes\n",
    "        regular_graph.add_edge(node, next_one)\n",
    "        regular_graph.add_edge(node, jump_node)\n",
    "\n",
    "    if draw:\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        nx.draw(regular_graph, pos=nx.circular_layout(regular_graph), with_labels=False)\n",
    "    return regular_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graph_comparisons_statistics(graph:nx.Graph):\n",
    "    equivalent_random = get_equivalent_random_graph(graph)\n",
    "    print_graph_statistics(equivalent_random)\n",
    "    equivalent_regular = get_equivalent_regular_graph(graph)\n",
    "    print_graph_statistics(equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1_equivalent_random = get_equivalent_random_graph(graph1, False)\n",
    "graph2_equivalent_random = get_equivalent_random_graph(graph2, False)\n",
    "graph3_equivalent_random = get_equivalent_random_graph(graph3, False)\n",
    "\n",
    "graph1_equivalent_regular = get_equivalent_regular_graph(graph1, False)\n",
    "graph2_equivalent_regular = get_equivalent_regular_graph(graph2, False)\n",
    "graph3_equivalent_regular = get_equivalent_regular_graph(graph3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph1_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(graph1_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(graph1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph2_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(graph2_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(graph2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(graph3_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(graph3_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(graph3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph1_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph2_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph3_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(graph3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_node_level_comparison(graph:nx.Graph, equivalent_random:nx.Graph, equivalent_regular:nx.Graph):\n",
    "\n",
    "    show_node_level_descriptors_degrees([graph, equivalent_random, equivalent_regular], ['graph', 'random', 'regular'])\n",
    "    print('\\n'*4)\n",
    "    show_node_level_descriptors_clustering_centrality([graph, equivalent_random, equivalent_regular], ['graph', 'random', 'regular'])\n",
    "    print('\\n'*4)\n",
    "    show_node_level_descriptors_closeness_centrality([graph, equivalent_random, equivalent_regular], ['graph', 'random', 'regular'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(graph1, graph1_equivalent_random, graph1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(graph2, graph2_equivalent_random, graph2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(graph3, graph3_equivalent_random, graph3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v) Two editors are connected iff they have both contributed to any thread in the same page, but not necessarily to the same thread? ( I.e. we would have more connections in the network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_connected_by_thread_in_same_page(network_data:str):\n",
    "    net = pd.read_csv(network_data)\n",
    "\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    for page, dataframe in net.groupby('page_name'):\n",
    "        nodes = dataframe['username'].unique()\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range (i + 1, len(nodes)):\n",
    "                graph.add_edge(nodes[i], nodes[j])\n",
    "\n",
    "    return graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - statistics\n",
    "#### - statistics of largest comp\n",
    "#### - node level stats\n",
    "#### - shortest paths (largest comp)\n",
    "#### - where on the regular <-> random network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = create_graph_connected_by_thread_in_same_page('datasets/PROPERTIES_FOR_DELETION_SML.csv')\n",
    "net2 = create_graph_connected_by_thread_in_same_page(\"datasets/WIKIPROJECTS_MED.csv\")\n",
    "net3 = create_graph_connected_by_thread_in_same_page(\"datasets/USERS_LRG.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(net1, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(net2, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(net3, with_labels = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(net1, 'Net 1', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(net2, 'Net 2', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh_plot_simple(net3, 'Net 3', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "print_graph_statistics(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics largest comp\n",
    "print_statistics_for_largest_component(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics_for_largest_component(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node level stats\n",
    "show_node_level_descriptors_degrees([net1, net2, net3], ['net1', 'net2', 'net3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_node_level_descriptors_clustering_centrality([net1, net2, net3], ['net1', 'net2', 'net3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_node_level_descriptors_closeness_centrality([net1, net2, net3], ['net1', 'net2', 'net3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest paths\n",
    "\n",
    "net1_largest_component = net1.subgraph(max(nx.connected_components(net1), key=len))\n",
    "\n",
    "net2_largest_component = net2.subgraph(max(nx.connected_components(net2), key=len))\n",
    "\n",
    "net3_largest_component = net3.subgraph(max(nx.connected_components(net3), key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if largest path is in largest component\n",
    "print('Net 1:')\n",
    "print(check_diam_is_in_component(net1, net1_largest_component))\n",
    "print('\\nNet 2: ')\n",
    "print(check_diam_is_in_component(net2, net2_largest_component))\n",
    "print('\\nNet 3:')\n",
    "print(check_diam_is_in_component(net3, net3_largest_component))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1_farthest_nodes  = get_farthest_nodes_efficient(net1_largest_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2_farthest_nodes  = get_farthest_nodes_efficient(net2_largest_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3_farthest_nodes  = get_farthest_nodes_efficient(net3_largest_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(net1_largest_component, net1_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(net2_largest_component, net2_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_Dijkstra(net3_largest_component, net3_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(net1_largest_component, net1_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(net2_largest_component, net2_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_shortest_path_largest_component_BF(net3_largest_component, net3_farthest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1_equivalent_random = get_equivalent_random_graph(net1, False)\n",
    "net2_equivalent_random = get_equivalent_random_graph(net2, False)\n",
    "net3_equivalent_random = get_equivalent_random_graph(net3, False)\n",
    "\n",
    "net1_equivalent_regular = get_equivalent_regular_graph(net1, False)\n",
    "net2_equivalent_regular = get_equivalent_regular_graph(net2, False)\n",
    "net3_equivalent_regular = get_equivalent_regular_graph(net3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net1_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(net1_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(net1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net2_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(net2_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(net2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_statistics(net3_equivalent_random)\n",
    "print('\\n')\n",
    "print_statistics_for_largest_component(net3_equivalent_random)\n",
    "print('\\n'*4)\n",
    "print_statistics_for_largest_component(net3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net1_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net2_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net3_equivalent_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_degree_count_distribution(net3_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(net1, net1_equivalent_random, net1_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(net2, net2_equivalent_random, net2_equivalent_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_node_level_comparison(net3, net3_equivalent_random, net3_equivalent_regular)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
