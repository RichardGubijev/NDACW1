{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Task C\n",
    "Within this task, we will use the network built from task A. Here each node will be a `username`, an edge can only exist iff 2 nodes has the commented at the same `page_name` and `thread_subject`\n",
    "\n",
    "Within this code it was aimed to find out the following\n",
    "- Unusual activity\n",
    "    - Define a criteria that says if the node has been involved in unusual activity aka commenting more than usual on the same day.\n",
    "    - Find nodes that comments more than usual, these are the infected nodes\n",
    "- Similarity Measure\n",
    "    - Define a measure that checks if the behaviour of a node has or has not propagated to other neighbouring nodes\n",
    "- Propagation\n",
    "    - For each of the nodes if they are risky show how plausible it is that it has propagated\n",
    "- Priority List"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:02:22.694148835Z",
     "start_time": "2024-02-27T12:02:22.102833228Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from taska import parseWikiData\n",
    "from helpers import get_2_semi_random_nodes, calculate_stats, calculate_jaccard_similarity\n",
    "from graph_helpers import display_graph, display_histogram, colours, get_colour, colour_count, plot_with_3_bars_per_bin\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "datasets = ['PROPERTIES_FOR_DELETION_SML.csv', 'WIKIPROJECTS_MED.csv','USERS_LRG.csv',]\n",
    "path = 'datasets/'\n",
    "networks = [parseWikiData(path + datasets[i]) for i in range(len(datasets))]\n",
    "\n",
    "network = 0\n",
    "G = networks[network]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T12:02:23.042132110Z",
     "start_time": "2024-02-27T12:02:22.666199929Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unusual activity\n",
    "This will be when someone is commenting more than unusual, so let's take a look at the statistics of the graph."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T12:02:23.048066442Z",
     "start_time": "2024-02-27T12:02:23.042908589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 739 nodes\n",
      "There is a total of 13530\n",
      "The mean degree of the graph is 36.617050067659\n",
      "The median degree of the graph is 23\n",
      "The max degree of the graph is 478\n"
     ]
    }
   ],
   "source": [
    "stats = calculate_stats(G)\n",
    "print(f\"There is a total of {len(G.nodes())} nodes\")\n",
    "print(f\"There is a total of {len(G.edges())}\")\n",
    "print(f\"The mean degree of the graph is {stats['mean_degree']}\")\n",
    "print(f\"The median degree of the graph is {stats['median_degree']}\")\n",
    "print(f\"The max degree of the graph is {stats['max_degree']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The variation here is great, most of the graphs the median is 1 while the mean is somewhat greater because of the max degree of the node.\n",
    "Some users will surely be hyperactive in the chats, therefore you can't say that a node is suspicious if it's greater than the mean or median.The measure here will be 1/4 of the max degree, just to assure that the user surly is suspicious. \n",
    "Then we can extract some nodes from the graph with a degree above the `degree_threshold`. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The editors currently marked as infected are ['Arbnos', 'Ivan A. Krestinin']\n",
      "Arbnos has a degree of 98\n",
      "Ivan A. Krestinin has a degree of 129\n"
     ]
    }
   ],
   "source": [
    "degree_threshold = int(stats['max_degree']/6)\n",
    "infected_nodes = get_2_semi_random_nodes(graph=G, threshold=degree_threshold)\n",
    "print(f\"The editors currently marked as infected are {infected_nodes}\")\n",
    "print(f\"{infected_nodes[0]} has a degree of {G.degree(infected_nodes[0])}\")\n",
    "print(f\"{infected_nodes[1]} has a degree of {G.degree(infected_nodes[1])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T12:02:23.052100063Z",
     "start_time": "2024-02-27T12:02:23.048046645Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Similarity measure\n",
    "Two measured are used together to define a similarity measure between the two nodes. This measure is called transmission risk as later on in the code we use this to define if the behaviour has propagated to neighbouring nodes. \n",
    "\n",
    "### Jaccard Similarity\n",
    "The first measure that's used is jaccard similarity. Jaccard similarity can be used to compare two groups to see how much they have in common. In our case we want to see if any of the infected nodes has similarities with their neighbours to define if they share the same trates as them to see if they also are indeed trolling. The formula for jaccard is defined below\n",
    "$$\n",
    "J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$$\n",
    "In our case A is the infected nodes neighbours and B is the selected nodes neighbours.\n",
    "It should also be mentioned that the closer the  Jaccard similarity is to 1, the more similar the nodes are, however if it's closer to 0, the 2 nodes doesn't have much in common. \n",
    "\n",
    "### Shortest path\n",
    "The shortest path is also considered as we don't only look on the nodes direct neighbours we look at all the nodes in the graph. \n",
    "\n",
    "### Transmission risk\n",
    "The general transmission risk is then calculated by doing.\n",
    "$$\n",
    "similarity=\\frac{jaccard_similarity}{shortest_path_length}\n",
    "$$ \n",
    "However a default value of 0 is returned if the degree of the node is below a degree threshold, as if it's below this threshold it means that the node e.g. only has one node, therefore shouldn't be marked as suspicious."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_transmission_risk(graph: nx.graph,\n",
    "                                infected_node: str,\n",
    "                                susceptible_node: str,\n",
    "                                threshold: int) -> float:\n",
    "    if nx.has_path(graph, infected_node, susceptible_node):\n",
    "        susceptible_node_neighbours = list(graph.neighbors(susceptible_node))\n",
    "        # if the degree is lower than a threshold the node isn't susceptible\n",
    "        if len(susceptible_node_neighbours) < threshold:\n",
    "            return 0.0\n",
    "        infected_node_neighbours = list(graph.neighbors(infected_node))\n",
    "        path_length = nx.shortest_path_length(graph, infected_node, susceptible_node)\n",
    "        similarity = calculate_jaccard_similarity(infected_node_neighbours,\n",
    "                                                  susceptible_node_neighbours)\n",
    "        risk = similarity / path_length\n",
    "        return risk\n",
    "    else:\n",
    "        return 0.0  # No path, no risk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T12:02:23.056680526Z",
     "start_time": "2024-02-27T12:02:23.053233342Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Propagation\n",
    "We need to calculate the transmission risk for all nodes that are risky, these are the nodes that has a risk greater than 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_risk_scores_of_valid_nodes(graph: nx.graph,\n",
    "                                   initially_infected: list[str],\n",
    "                                   susceptible_editors: list[str],\n",
    "                                   threshold: int) -> dict:\n",
    "    transmission_risk_scores = {}\n",
    "    for infected in initially_infected:\n",
    "        for susceptible in susceptible_editors:\n",
    "            risk = calculate_transmission_risk(graph, infected, susceptible, threshold)\n",
    "            if risk == 0:\n",
    "                pass\n",
    "            elif risk not in transmission_risk_scores:\n",
    "                transmission_risk_scores[susceptible] = risk\n",
    "            else:\n",
    "                current_risk = transmission_risk_scores[susceptible]\n",
    "                transmission_risk_scores[susceptible] = max(current_risk, risk)\n",
    "    return transmission_risk_scores\n",
    "\n",
    "all_nodes = [node for node in G.nodes() if node not in infected_nodes]\n",
    "risky_nodes = get_risk_scores_of_valid_nodes(G, infected_nodes, all_nodes, stats['median_degree'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T12:02:23.130505032Z",
     "start_time": "2024-02-27T12:02:23.085597977Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's make a new graph with only the nodes that are risky."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_risk_graph(old_graph: nx.graph, nodes: dict, nodes_infected: list) -> nx.graph:\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(nodes_infected, color=colours[0])\n",
    "    node_keys = set(nodes.keys())\n",
    "    appended_nodes = set()\n",
    "    for node in nodes:\n",
    "        graph.add_node(node, color=get_colour(nodes[node]))\n",
    "    for node in node_keys:\n",
    "        for infected in nodes_infected:\n",
    "            shortest_path = nx.shortest_path(old_graph, source=infected, target=node)\n",
    "            if len(shortest_path) == 2:\n",
    "                graph.add_edge(shortest_path[0], shortest_path[1])\n",
    "            else:\n",
    "                for i in range(len(shortest_path) - 1):\n",
    "                    next_elem = shortest_path[i + 1]\n",
    "                    if (next_elem not in node_keys\n",
    "                            and next_elem not in nodes_infected\n",
    "                            and next_elem not in appended_nodes):\n",
    "                        appended_nodes.add(next_elem)\n",
    "                        graph.add_node(shortest_path[i + 1], color=colours[6])\n",
    "                    graph.add_edge(shortest_path[i], shortest_path[i + 1])\n",
    "    return graph\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T12:02:23.131414176Z",
     "start_time": "2024-02-27T12:02:23.130398264Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's have a look on how the nodes are connected and their belonging similarity measure.\n",
    "In most instances here there will be loads of nodes, so the histogram will be a better representation of the similarity distribution.\n",
    "The darker red color and the greater the similarity the more likely it is that node possibly has been trolling.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "new_graph = generate_risk_graph(G, risky_nodes, infected_nodes)\n",
    "display_graph(new_graph)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-27T12:02:23.130686228Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also have a look on the distribution between the different similarity measure ranges as a histogram. \n",
    "We can see in most instances that most of the nodes aren't that similar to any of the infected nodes. These are then probably not trolls either."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "display_histogram(new_graph)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Propagation\n",
    "The way we can make a priority list is to sort the list of risky nodes with respect to the similarity measure."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sorted_data = sorted(risky_nodes.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "print(\"The 10 first nodes that are the riskiest are:\")\n",
    "for node in sorted_data[:10]:\n",
    "    print(node)\n",
    "\n",
    "# saving the data as a csv file\n",
    "with open('analysed_nodes.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['username', 'similarity'])\n",
    "    for key, value in sorted_data:\n",
    "        writer.writerow([key, value])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison \n",
    "We want to get the statistics of multiple runs for further analysis. The steps to achieve this is o:\n",
    "1. Run 10 instances of the algorithm defined above and save the risk_graph.\n",
    "2. Make an average for each of the similarity ranges\n",
    "3. Display the histogram\n",
    "\n",
    "### Run multiple runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Run 10 instances for each of the 3 networks\n",
    "\n",
    "network: int = 0\n",
    "graphs: dict = {}\n",
    "iterations: int = 10\n",
    "nodes_in_each_graph = {}\n",
    "\n",
    "for i in range(3):\n",
    "    G = networks[i]\n",
    "    stats = calculate_stats(G)\n",
    "    nodes_in_each_graph[i] = len(G.nodes())\n",
    "    degree_threshold = int(stats['max_degree']/8)\n",
    "    graphs[i] = []   \n",
    "    for j in range(iterations):\n",
    "        infected_nodes = get_2_semi_random_nodes(graph=G, threshold=degree_threshold)\n",
    "        all_nodes = [node for node in G.nodes() if node not in infected_nodes]\n",
    "        risky_nodes = get_risk_scores_of_valid_nodes(G, infected_nodes, all_nodes, stats['median_degree'])\n",
    "        risk_graph = generate_risk_graph(G, risky_nodes, infected_nodes)\n",
    "        graphs[i].append(colour_count(risk_graph))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Average similarity "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "averages = {}\n",
    "\n",
    "# Sum the values for each unique colour for each network\n",
    "for outer_key, inner_list in graphs.items():\n",
    "    averages[outer_key] = {}\n",
    "    for inner_dict in inner_list:\n",
    "        for color, count in inner_dict.items():\n",
    "            if color not in averages[outer_key]:\n",
    "                averages[outer_key][color] = count\n",
    "            else:\n",
    "                current_sum = averages[outer_key][color]\n",
    "                new_count = current_sum + count\n",
    "                averages[outer_key][color] = new_count\n",
    "\n",
    "# Take the average for each colour within each network\n",
    "for i in averages:\n",
    "    for j in averages[i]:\n",
    "        averages[i][j] = int(averages[i][j]/iterations)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting similarity ranges for the runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_with_3_bars_per_bin(averages, \n",
    "                         datasets,\n",
    "                         'Similarity',\n",
    "                         'similar occurrences',\n",
    "                         f'Average similar for {iterations} runs')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "average_percentages = averages\n",
    "for network_id in average_percentages:\n",
    "    for colour in average_percentages[network_id]:\n",
    "        average_percentages[network_id][colour] = (average_percentages[network_id][colour]/nodes_in_each_graph[network_id])*100\n",
    "        \n",
    "plot_with_3_bars_per_bin(average_percentages, \n",
    "                         datasets,\n",
    "                         \"Similarity\",\n",
    "                         \"Node percentage similarity\",\n",
    "                         f\"Average similar with {iterations} runs for percentage of nodes\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
